{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ff2622",
   "metadata": {},
   "source": [
    "# Step 5. Modelling and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382039fe",
   "metadata": {},
   "source": [
    "## Question:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e697875e",
   "metadata": {},
   "source": [
    "#### Can we accurately predict the number of awards issued per 100 full-time undergraduate students at higher education institutions using institutional characteristics as predictors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a1127",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae309fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from datetime import datetime, date\n",
    "from scipy.stats import randint\n",
    "import warnings  \n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d7864",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923e2fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student_count  awards_per_value  awards_per_state_value  \\\n",
      "0           4051                14                    18.8   \n",
      "1          11502                20                    18.8   \n",
      "2            322                29                    17.8   \n",
      "3           5696                20                    18.8   \n",
      "4           5356                11                    18.8   \n",
      "\n",
      "   awards_per_natl_value  exp_award_value  exp_award_state_value  \\\n",
      "0                   21.5         105331.0                  75743   \n",
      "1                   21.5         136546.0                  75743   \n",
      "2                   22.5          58414.0                  92268   \n",
      "3                   21.5          64418.0                  75743   \n",
      "4                   21.5         132407.0                  75743   \n",
      "\n",
      "   exp_award_natl_value  ft_pct  fte_value  aid_value  ...  grad_150_value  \\\n",
      "0                 66436    93.8       3906     7142.0  ...              29   \n",
      "1                 66436    72.7       2157     6088.0  ...              53   \n",
      "2                101725    62.7        294     2540.0  ...              66   \n",
      "3                 66436    74.4       5000     6647.0  ...              48   \n",
      "4                 66436    91.0       5035     7256.0  ...              25   \n",
      "\n",
      "   pell_value  retain_value  ft_fac_value  state_sector_ct  carnegie_ct  \\\n",
      "0        71.2            63          82.8             13.0          386   \n",
      "1        35.1            80          92.4             13.0          106   \n",
      "2        68.4            37          67.2             16.0          252   \n",
      "3        32.8            81          65.5             13.0          106   \n",
      "4        82.7            62          67.0             13.0          386   \n",
      "\n",
      "   counted_pct  cohort_size  num_similar  public  \n",
      "0         99.7          882           20       1  \n",
      "1         56.0         1376           20       1  \n",
      "2        100.0            3           20       0  \n",
      "3         43.1          759           20       1  \n",
      "4         88.0         1351           20       1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('preprocessed_collegedata.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cad868",
   "metadata": {},
   "source": [
    "## Train/Test Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b92e6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3038, 21), (760, 21))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['awards_per_value'])\n",
    "y = df['awards_per_value']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a4fa0",
   "metadata": {},
   "source": [
    "## Scaled X_train, X_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc86fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e796e93",
   "metadata": {},
   "source": [
    "## Train/test several Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eaa2e8",
   "metadata": {},
   "source": [
    "### The Evaluation Metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79fcff",
   "metadata": {},
   "source": [
    "- **R-squared:** Higher values indicate a better fit of the model to the data.\n",
    "- **MSE(Mean Squared Error) and RMSE(Root Mean Squared Error)**: Lower values indicate better model performance.\n",
    "- **AIC(Akaike Information Criterion) and BIC(Bayesian Information Criterion):** Lower values indicate a better model when penalizing for the number of parameters. AIC takes into consideration a trade-off between model fit and its complexity and BIC prioritzes simpler models, hence a stronger penalty for complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129fdab0",
   "metadata": {},
   "source": [
    "### The Baseline Model: *The mean.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1007ed29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test MSE:  42.72236842105263\n",
      "Baseline Test RMSE:  6.5362350341043145\n",
      "Baseline Test R^2 score:  -2.5328444065664257e-05\n",
      "Baseline AIC: 5012.3757720700905\n",
      "Baseline BIC: 5017.009090503371\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of the target variable\n",
    "y_mean = np.mean(y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred_baseline = np.full_like(y_test, y_mean)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_b = mean_squared_error(y_test, y_pred_baseline)\n",
    "rmse_b = np.sqrt(mse_b)\n",
    "r2_b = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "# Calculate the log-likelihood\n",
    "log_likelihood_b = -0.5 * np.sum(np.log(2 * np.pi * mse_b) + (y_test - y_pred_baseline) ** 2 / mse_b)\n",
    "\n",
    "# Number of parameters\n",
    "k_b = 1 #1 for the mean\n",
    "\n",
    "# Sample size\n",
    "n_b = len(y_test)\n",
    "\n",
    "# Calculate AIC and BIC\n",
    "aic_b = -2 * log_likelihood_b + 2 * k_b\n",
    "bic_b = -2 * log_likelihood_b + k_b * np.log(n_b)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Baseline Test MSE: \", mse_b)\n",
    "print(\"Baseline Test RMSE: \", rmse_b)\n",
    "print(\"Baseline Test R^2 score: \", r2_b)\n",
    "print(\"Baseline AIC:\", aic_b)\n",
    "print(\"Baseline BIC:\", bic_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab082d7",
   "metadata": {},
   "source": [
    "- A negative R-squared suggests that the model performs poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28109345",
   "metadata": {},
   "source": [
    "### ML Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38550d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Elastic Net': ElasticNet(),\n",
    "    'SVR': SVR()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464b93e",
   "metadata": {},
   "source": [
    "**(a). Using unscaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc66a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: RMSE = 5.359441840192864\n",
      "Ridge Regression: RMSE = 5.3595327871102185\n",
      "Lasso Regression: RMSE = 5.384823298535275\n",
      "Decision Tree: RMSE = 7.0483294026613885\n",
      "Random Forest: RMSE = 4.873973886611255\n",
      "Gradient Boosting: RMSE = 4.9938618958272745\n",
      "Elastic Net: RMSE = 5.386298905036575\n",
      "SVR: RMSE = 5.968143509928486\n"
     ]
    }
   ],
   "source": [
    "# Train and test the models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred1 = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred1)\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    results[name] = rmse\n",
    "\n",
    "# Results\n",
    "for name, rmse in results.items():\n",
    "    print(f'{name}: RMSE = {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae75fba",
   "metadata": {},
   "source": [
    "**(b). Using scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c1fe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: RMSE = 5.3594418401929405\n",
      "Ridge Regression: RMSE = 5.35945079345077\n",
      "Lasso Regression: RMSE = 5.767405839321374\n",
      "Decision Tree: RMSE = 6.814651398583094\n",
      "Random Forest: RMSE = 4.898480484051312\n",
      "Gradient Boosting: RMSE = 4.986349100930348\n",
      "Elastic Net: RMSE = 5.66861080535132\n",
      "SVR: RMSE = 5.021728838208683\n"
     ]
    }
   ],
   "source": [
    "# Train and test the models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred2 = model.predict(X_test_scaled)\n",
    "    mse2 = mean_squared_error(y_test, y_pred2)\n",
    "    # Calculate RMSE\n",
    "    rmse2 = np.sqrt(mse2)\n",
    "    results[name] = rmse2\n",
    "\n",
    "# Results\n",
    "for name, rmse2 in results.items():\n",
    "    print(f'{name}: RMSE = {rmse2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb175c8d",
   "metadata": {},
   "source": [
    "**- Based on the REMSE metric, Random Forest Regression model has the best overall performance while Gradient Boosting Regression is the second best. In the following work, these two models are explored further through hyperparameter tuning. These two models are expensive when searching for optimal parametors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff3ba7",
   "metadata": {},
   "source": [
    "## Model 1. Random Forest Regression, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f067ab0",
   "metadata": {},
   "source": [
    "**(a). Find optimal parameters for the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eea1162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:  2024-06-29 02:45:56.060477\n",
      "End time:  2024-06-29 02:51:50.044613\n",
      "Best parameters found by GridSearchCV:  {'max_depth': 9, 'max_features': 'sqrt', 'n_estimators': 300, 'random_state': 21}\n",
      "Best score from GridSearchCV:  0.4341585257433283\n"
     ]
    }
   ],
   "source": [
    "# Define Grid \n",
    "grid = { \n",
    "    'n_estimators': [300,400],\n",
    "    'max_features': ['sqrt','log2'],\n",
    "    'max_depth' : [5,6,7,8,9],\n",
    "    'random_state' : [21]}\n",
    "#Start time\n",
    "print(\"Start time: \", datetime.now())\n",
    "# Grid Search function\n",
    "CV_rfr = GridSearchCV(estimator=RandomForestRegressor(), param_grid=grid, cv= 5)\n",
    "CV_rfr.fit(X_train, y_train)\n",
    "#End time\n",
    "print(\"End time: \", datetime.now())\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters found by GridSearchCV: \", CV_rfr.best_params_)\n",
    "print(f\"Best score from GridSearchCV: \", CV_rfr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bdfb36",
   "metadata": {},
   "source": [
    "**(b). Tune and evaluate the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170c9d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE for GridSearchCV:  23.62416855138193\n",
      "Test RMSE for GridSearchCV:  4.860469992848627\n",
      "Test R^2 score for GridSearchCV:  0.44701645091445996\n",
      "AIC: 4568.111982638933\n",
      "BIC: 4586.645256372055\n"
     ]
    }
   ],
   "source": [
    "#Optimal params\n",
    "rf_params = CV_rfr.best_params_\n",
    "\n",
    "# Fit model with best parameters\n",
    "rf = RandomForestRegressor(**rf_params)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Compute mean squared error\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Calculate the log-likelihood\n",
    "log_likelihood_rf = -0.5 * np.sum(np.log(2 * np.pi * mse_rf) + (y_test - y_pred_rf) ** 2 / mse_rf)\n",
    "\n",
    "# Number of parameters\n",
    "n_params_rf = len(rf_params)\n",
    "\n",
    "# Compute AIC and BIC\n",
    "n_samples_rf = len(y_test)\n",
    "aic_rf = -2 * log_likelihood_rf + 2 * n_params_rf\n",
    "bic_rf = -2 * log_likelihood_rf + n_params_rf * np.log(n_samples_rf)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Test MSE for GridSearchCV: \", mse_rf)\n",
    "print(\"Test RMSE for GridSearchCV: \", rmse_rf)\n",
    "print(\"Test R^2 score for GridSearchCV: \", r2_rf)\n",
    "print(f\"AIC: {aic_rf}\")\n",
    "print(f\"BIC: {bic_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a800a",
   "metadata": {},
   "source": [
    "## Model 2. Random Forest Regression, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfadd57",
   "metadata": {},
   "source": [
    "**(a). Find the optimal parameters for the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb9340b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2024-06-29 02:51:53.958775\n",
      "End time: 2024-06-29 02:58:50.540689\n",
      "Best parameters found:  {'max_depth': 9, 'max_features': 'sqrt', 'n_estimators': 393, 'random_state': 21}\n",
      "Best score:  0.43379214697641777\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "random_grid = { \n",
    "    'n_estimators': randint(200, 600),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': randint(3, 10),\n",
    "    'random_state': [21]\n",
    "}\n",
    "# Show start time\n",
    "print(\"Start time:\", datetime.now())\n",
    "\n",
    "# Perform random search\n",
    "r_search = RandomizedSearchCV(estimator=RandomForestRegressor(), \n",
    "                              param_distributions=random_grid, n_iter=100, cv=5, random_state=21, n_jobs=-1)\n",
    "r_search.fit(X_train, y_train)\n",
    "\n",
    "# Show end time\n",
    "print(\"End time:\", datetime.now())\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", r_search.best_params_)\n",
    "\n",
    "# Print the best score\n",
    "print(\"Best score: \", r_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d893ae",
   "metadata": {},
   "source": [
    "**(b). Tune the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97655fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  23.598479353494678\n",
      "Test RMSE:  4.8578266080104875\n",
      "Test R^2 score:  0.4476177717097276\n",
      "AIC: 4567.285100065148\n",
      "BIC: 4585.81837379827\n"
     ]
    }
   ],
   "source": [
    "#Best parameters\n",
    "optimal_p2 = r_search.best_params_ \n",
    "\n",
    "# Fit model with best parameters\n",
    "model2 = RandomForestRegressor(**optimal_p2)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred4 = model2.predict(X_test)\n",
    "\n",
    "# Calculate the MSE\n",
    "mse4 = mean_squared_error(y_test, y_pred4)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse4 = np.sqrt(mse4)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2_4 = r2_score(y_test, y_pred4)\n",
    "\n",
    "# Calculate the log-likelihood\n",
    "log_likelihood_4 = -0.5 * np.sum(np.log(2 * np.pi * mse4) + (y_test - y_pred4) ** 2 / mse4)\n",
    "\n",
    "# Number of parameters\n",
    "k4 = len(optimal_p2)\n",
    "\n",
    "#Sample size\n",
    "n4 = len(y_test)\n",
    "\n",
    "# Calculate AIC and BIC\n",
    "aic_4 = -2 * log_likelihood_4 + 2 * k4\n",
    "bic_4 = -2 * log_likelihood_4 + k4 * np.log(n4)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Test MSE: \", mean_squared_error(y_test, y_pred4))\n",
    "print(\"Test RMSE: \", rmse4)\n",
    "print(\"Test R^2 score: \", r2_4)\n",
    "print(\"AIC:\", aic_4)\n",
    "print(\"BIC:\", bic_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c05b40",
   "metadata": {},
   "source": [
    "## Model 3. Gradient Boosting Regression, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6dcc42",
   "metadata": {},
   "source": [
    "**(a). Find optimal parameters for the Model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52f944ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2024-06-29 02:58:58.052635\n",
      "End time: 2024-06-29 03:00:10.382307\n",
      "Best parameters found for GBR model:  {'learning_rate': 0.1, 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 200}\n",
      "Best score (negative MSE):  -24.450882845060256\n"
     ]
    }
   ],
   "source": [
    "#Define parameters\n",
    "g_params_grid = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'max_features': ['sqrt', 'log2']} \n",
    "\n",
    "# Start time\n",
    "print(\"Start time:\", datetime.now())\n",
    "\n",
    "# Perform grid search\n",
    "gbr_search = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=g_params_grid, cv=5, \n",
    "                          n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "gbr_search.fit(X_train, y_train)\n",
    "\n",
    "# End time\n",
    "print(\"End time:\", datetime.now())\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found for GBR model: \", gbr_search.best_params_)\n",
    "\n",
    "# Print the best score (negative MSE)\n",
    "print(\"Best score (negative MSE): \", gbr_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2990db",
   "metadata": {},
   "source": [
    "**(b). Tune the Model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8243fc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 23.354354719619096\n",
      "Test RMSE:  4.832634345739298\n",
      "Test R^2 score:  0.4533321275892208\n",
      "AIC:  4559.382003380608\n",
      "BIC:  4577.91527711373\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "g_params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_features\": 'sqrt'\n",
    "}\n",
    "\n",
    "# Fit the model\n",
    "gbr = GradientBoostingRegressor(**g_params)\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred6 = gbr.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse6 = mean_squared_error(y_test, y_pred6)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse6 = np.sqrt(mse6)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2_s = r2_score(y_test, y_pred6)\n",
    "\n",
    "\n",
    "# Calculate AIC and BIC \n",
    "# Number of observations\n",
    "n_samples_6 = len(y_test)\n",
    "\n",
    "# Number of parameters\n",
    "k = len(g_params)\n",
    "\n",
    "# Calculate log-likelihood\n",
    "log_likelihood_gbr = -0.5 * np.sum(np.log(2 * np.pi * mse6) + (y_test - y_pred6) ** 2 / mse6)\n",
    "\n",
    "aic_gbr = 2 * k - 2 * log_likelihood_gbr\n",
    "bic_gbr = np.log(n_samples_6) * k - 2 * log_likelihood_gbr\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Test MSE: {mse6}\")\n",
    "print(\"Test RMSE: \", rmse6)\n",
    "print(\"Test R^2 score: \", r2_s)\n",
    "print(\"AIC: \", aic_gbr)\n",
    "print(\"BIC: \", bic_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32cf187",
   "metadata": {},
   "source": [
    "## Model 4. Gradient Boosting Regression, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b6992",
   "metadata": {},
   "source": [
    "**(a). Find the best parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f1b5308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2024-06-29 03:00:15.650348\n",
      "End time: 2024-06-29 03:15:08.333050\n",
      "Best parameters found:  {'learning_rate': 0.021174945340976328, 'max_depth': 9, 'max_features': 'log2', 'n_estimators': 454}\n",
      "Best score (negative MSE):  -23.317623907773005\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "# Define parameter distribution for RandomizedSearchCV\n",
    "params = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]}\n",
    "\n",
    "# Start time\n",
    "print(\"Start time:\", datetime.now())\n",
    "\n",
    "# Perform random search\n",
    "random_search_gbr = RandomizedSearchCV(estimator=GradientBoostingRegressor(), param_distributions=params, \n",
    "                                   n_iter=100, cv=5, random_state=21, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "random_search_gbr.fit(X_train, y_train)\n",
    "\n",
    "# End time\n",
    "print(\"End time:\", datetime.now())\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", random_search_gbr.best_params_)\n",
    "\n",
    "# Print the best score (negative MSE)\n",
    "print(\"Best score (negative MSE): \", random_search_gbr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32496977",
   "metadata": {},
   "source": [
    "**(b). Tune the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9dec96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared:  0.4702186807771006\n",
      "Test MSE: 22.63293944529122\n",
      "Test RMSE: 4.7574089003670075\n",
      "AIC: 4535.535390952612\n",
      "BIC: 4554.068664685734\n"
     ]
    }
   ],
   "source": [
    "#Fit the model with best parameters\n",
    "optimal_params = random_search_gbr.best_params_\n",
    "model_tuned = GradientBoostingRegressor(**optimal_params)\n",
    "model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_tuned = model_tuned.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_t = mean_squared_error(y_test, y_pred_tuned)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_t = np.sqrt(mse_t)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2_scored = r2_score(y_test, y_pred_tuned)\n",
    "print(\"Test R-squared: \", r2_scored)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_tuned = model_tuned.predict(X_test)\n",
    "\n",
    "# Calculate the log-likelihood\n",
    "log_likelihood_t = -0.5 * np.sum(np.log(2 * np.pi * mse_t) + (y_test - y_pred_tuned) ** 2 / mse_t)\n",
    "\n",
    "# Number of parameters\n",
    "num_params_t = len(optimal_params)\n",
    "\n",
    "# Calculate AIC and BIC\n",
    "n_samples_t = len(y_test)\n",
    "aic_t = -2 * log_likelihood_t + 2 * num_params_t\n",
    "bic_t = -2 * log_likelihood_t + num_params_t * np.log(n_samples_t)\n",
    "\n",
    "print(f\"Test MSE: {mse_t}\")\n",
    "print(f\"Test RMSE: {rmse_t}\")\n",
    "print(f\"AIC: {aic_t}\")\n",
    "print(f\"BIC: {bic_t}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01f8853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: texttable in c:\\users\\mtides\\anaconda3\\lib\\site-packages (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install texttable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "413e4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import texttable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82f5e0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------+--------+-------+----------+----------+\n",
      "|         Model         | R-squared |  MSE   | RMSE  |   AIC    |   BIC    |\n",
      "+=======================+===========+========+=======+==========+==========+\n",
      "| Baseline              | -0.000    | 47.720 | 6.540 | 5012.380 | 5017     |\n",
      "+-----------------------+-----------+--------+-------+----------+----------+\n",
      "| RFRGridSearchCV       | 0.450     | 23.620 | 4.860 | 4568.110 | 4586.650 |\n",
      "+-----------------------+-----------+--------+-------+----------+----------+\n",
      "| RFRRandomizedSearchCV | 0.450     | 23.600 | 4.860 | 4567.290 | 4585.810 |\n",
      "+-----------------------+-----------+--------+-------+----------+----------+\n",
      "| GBRGridSearchCV       | 0.450     | 23.350 | 4.830 | 4559.380 | 4577.920 |\n",
      "+-----------------------+-----------+--------+-------+----------+----------+\n",
      "| GBRRandomizedSearchCV | 0.470     | 22.630 | 4.760 | 4535.540 | 4554.070 |\n",
      "+-----------------------+-----------+--------+-------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Create a texttable object\n",
    "tableO = texttable.Texttable()\n",
    "\n",
    "# Add rows to the table\n",
    "tableO.add_rows([\n",
    "    ['Model', 'R-squared', 'MSE', 'RMSE', 'AIC', 'BIC'],\n",
    "    ['Baseline', -2.53e-05, 47.72, 6.54, 5012.38, 5017],\n",
    "    ['RFRGridSearchCV', 0.45, 23.62, 4.86, 4568.11, 4586.65],\n",
    "    ['RFRRandomizedSearchCV', 0.45, 23.60, 4.86, 4567.29, 4585.81],\n",
    "    ['GBRGridSearchCV', 0.45, 23.35, 4.83, 4559.38, 4577.92],\n",
    "    ['GBRRandomizedSearchCV', 0.47, 22.63, 4.76, 4535.54, 4554.07]\n",
    "])\n",
    "\n",
    "# Print the table\n",
    "print(tableO.draw())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc93269",
   "metadata": {},
   "source": [
    "## Model Comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c777e",
   "metadata": {},
   "source": [
    "- **Baseline Model:** The R-squared is extremely low (-2.53e-05), indicating it does not explain the variance in the data well. Since it has the highest MSE, RMSE, AIC, and BIC, it shows it performs the worst.\n",
    "- **Random Forest Regression, GridSearchCV and Random Forest Regression, RandomizedSearchCV:** These models have similar performance with identical R-squared and RMSE. However, Random Forest Regression, RandomizedSearchCV has slightly lower MSE, AIC, and BIC.\n",
    "- **Gradient Boosting Regression, GridSearchCV** shows better performance than the previous two models and the baseline model. It has a higher R-squared, lower MSE, RMSE, AIC, and BIC.\n",
    "- **Gradient Boosting Regression, RandomizedSearcgCV** is the best performing among all the models. It has the highest coefficient of determination and the lowest MSE, RMSE, AIC, and BIC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92a22f",
   "metadata": {},
   "source": [
    "## Conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1951e37d",
   "metadata": {},
   "source": [
    "Based on the provided evaluation metrics, **Gradient Boosting Regression, RandomizedSearcgCV** is the best model. It has the highest R-squared (0.47), indicating it explains the most variance in the data. It also has the lowest Mean Squared Error (22.63), Root Mean Squared Error (4.76), Akaike Information Criterion (4535.54), and Bayesian Information Criterion (4554.07), suggesting it performs best in terms of accuracy and model fit while considering model complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
